{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Notebook To Accompany the centgovspend Library\n",
    "\n",
    "This is a notebook to accompany the [centgovspend](https://github.com/crahal/centgovspend/) project. It first imports data and necessary libraries/modules, then outputs some summary statistics and a longitudinal over-view of the data which is aggregated by the library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Importing Data and Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets first load our favourite tools! Everything here is pretty much bundled with Anaconda other than gender_guesser (```pip install gender_guesser```) and ezodf (```pip install ezodf```).A requirements.txt accompanies [the repository](http://github.com/crahal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import seaborn as sns\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "from clean_matches import clean_matches\n",
    "import matplotlib as mpl\n",
    "import gender_guesser.detector as gender\n",
    "gendet = gender.Detector()\n",
    "sns.set(style='ticks')\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then lets load the main payments and reconciliation datasets generated by the library (```centgovspend/src/centgovspend·py```):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "payments = pd.read_csv(os.path.abspath(\n",
    "    os.path.join('__file__', '../..', 'data', 'output', 'master',\n",
    "                 'All_Merged_Unmatched.csv')),\n",
    "    encoding=\"ISO-8859-1\", sep=',', engine='python',\n",
    "    dtype={'transactionnumber': str,\n",
    "           'supplier': str,\n",
    "           'date': str,\n",
    "           'expensearea': str,\n",
    "           'expensetype': str,\n",
    "           'file': str,\n",
    "           'amount': float})\n",
    "payments['date'] = payments['date'].apply(pd.to_datetime,\n",
    "                                          dayfirst=True,\n",
    "                                          errors = 'coerce')\n",
    "replacedict = pd.read_csv((os.path.abspath(\n",
    "    os.path.join('__file__', '../..', 'data',\n",
    "                 'support', 'dept_names_dict.csv'))),\n",
    "                          header=None,\n",
    "                          dtype={0: str}).set_index(0).squeeze().to_dict()\n",
    "for key, value in replacedict.items():\n",
    "    payments['dept'] = payments['dept'].replace(key,value)\n",
    "    \n",
    "recon_sup = pd.read_csv(os.path.abspath(\n",
    "    os.path.join('__file__', '../..', 'data', 'output',\n",
    "                 'master', 'Reconciled_Suppliers.tsv')),\n",
    "    encoding=\"ISO-8859-1\", sep='\\t')\n",
    "recon_sup = recon_sup.drop(['Disputed Office', 'Third Match',\n",
    "                            'Third ID', 'Third Score'], axis=1)\n",
    "matched = pd.merge(payments, recon_sup, how='left', left_on='supplier',\n",
    "    right_on='RawSupplier').dropna(subset=['Best Match'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets print out some summary statistics from just the parsed datasets. These should more or less match the print --> stdout commands generated by ```centgovspend/src/centgovspend·py```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('We matched ' + str(len(matched)) + ' out of ' + str(len(payments)) +\n",
    "      ' payments in total (' + str(round(((len(matched) /\n",
    "                                           len(payments)) * 100), 2)) + '%).')\n",
    "print('We matched £' + str(int(matched['amount'].sum())) + ' out of ' +\n",
    "      '£' + str(int(payments['amount'].sum())) +\n",
    "      ' value in total (' + str(int(round(((matched['amount'].sum() /\n",
    "                                        payments['amount'].sum()) *\n",
    "                                       100), 2))) + '%).')\n",
    "print('We matched ' + str(len(matched['supplier'].unique())) + ' out of ' +\n",
    "      str(len(payments['supplier'].unique())) +\n",
    "      ' unique suppliers in total (' +\n",
    "      str(round(((len(matched['supplier'].unique()) /\n",
    "                  len(payments['supplier'].unique())) * 100), 2)) + '%).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Longitidinal Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets analyze the bounty of procurement data which we ourselves have procured, and overlay the three critical policy junctures at different points in time. In general note that we are saving .pdfs for the TeX paper, and .pngs to be hosted and called by the readme.md of the repo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timely_df = pd.DataFrame(columns=['Number of Payments', 'Value of Payments'])\n",
    "numberpayments = 0\n",
    "valuepayments = 0\n",
    "for year in list(range(2009, 2018)):\n",
    "    timely_df.at[str(year) + 'Q1', 'Number of Payments'] = len(payments[\n",
    "        (payments['date'].dt.month <= 3) &\n",
    "        (payments['date'].dt.year == year)])\n",
    "    timely_df.at[str(year) + 'Q1', 'Value of Payments'] = payments[\n",
    "        (payments['date'].dt.month <= 3) &\n",
    "        (payments['date'].dt.year == year)]['amount'].sum()\n",
    "    timely_df.at[str(year) + 'Q2', 'Number of Payments'] = len(payments[\n",
    "        (3 < payments['date'].dt.month) &\n",
    "        (payments['date'].dt.month <= 6) &\n",
    "        (payments['date'].dt.year == year)])\n",
    "    timely_df.at[str(year) + 'Q2', 'Value of Payments'] = payments[\n",
    "        (3 < payments['date'].dt.month) &\n",
    "        (payments['date'].dt.month <= 6) &\n",
    "        (payments['date'].dt.year == year)]['amount'].sum()\n",
    "    timely_df.at[str(year) + 'Q3', 'Number of Payments'] = len(payments[\n",
    "        (6 < payments['date'].dt.month) &\n",
    "        (payments['date'].dt.month <= 9) &\n",
    "        (payments['date'].dt.year == year)])\n",
    "    timely_df.at[str(year) + 'Q3', 'Value of Payments'] = payments[\n",
    "        (6 < payments['date'].dt.month) &\n",
    "        (payments['date'].dt.month <= 9) &\n",
    "        (payments['date'].dt.year == year)]['amount'].sum()\n",
    "    timely_df.at[str(year) + 'Q4', 'Number of Payments'] = len(payments[\n",
    "        (9 < payments['date'].dt.month) &\n",
    "        (payments['date'].dt.month <= 12) &\n",
    "        (payments['date'].dt.year == year)])\n",
    "    timely_df.at[str(year) + 'Q4', 'Value of Payments'] = payments[\n",
    "        (9 < payments['date'].dt.month) &\n",
    "        (payments['date'].dt.month <= 12) &\n",
    "        (payments['date'].dt.year == year)]['amount'].sum()\n",
    "timley_resetindex = timely_df.reset_index()\n",
    "fig = plt.figure(figsize=(12, 6), dpi=800)\n",
    "axC = fig.add_subplot(1, 1, 1)\n",
    "ax_2a = timley_resetindex[['Value of Payments']].plot(kind='area',\n",
    "                                                      ax=axC,\n",
    "                                                      color='#377eb8',\n",
    "                                                      legend=False,\n",
    "                                                      alpha=0.225)\n",
    "ax_2b = timley_resetindex[['Number of Payments']].plot(kind='area',\n",
    "                                                       ax=axC.twinx(),\n",
    "                                                       color='#ff7f00',\n",
    "                                                       legend=False,\n",
    "                                                       alpha=0.225)\n",
    "ax_2a.set_xticks(timley_resetindex.index)\n",
    "ax_2a.set_xticklabels(timley_resetindex['index'], rotation=90)\n",
    "ax_2a.vlines(x=5.66, ymin=0,\n",
    "             ymax=timley_resetindex['Value of Payments'].max()/0.8,\n",
    "             color='k', linestyle='--',\n",
    "             alpha=0.5, linewidth=0.85)\n",
    "ax_2a.annotate('31/05/2010:\\nCameron\\noutlines\\ntransparency',\n",
    "               xy=(5.66, timley_resetindex['Value of Payments'].max()/0.925),\n",
    "               xytext=(1.66, timley_resetindex['Value of Payments'].max()/0.925),\n",
    "               arrowprops=dict(color='k', arrowstyle=\"->\", alpha=0.95), size=9)\n",
    "ax_2a.vlines(x=7.2, ymin=0,\n",
    "             ymax=timley_resetindex['Value of Payments'].max()/0.8,\n",
    "             color='k', linestyle='--',\n",
    "             alpha=0.5, linewidth=0.85)\n",
    "ax_2a.annotate('20/10/2010:\\nOsborne decides\\nto \"wield the\\naxe\"',\n",
    "               xy=(7.2, timley_resetindex['Value of Payments'].max()/0.925),\n",
    "               xytext=(9, timley_resetindex['Value of Payments'].max()/0.925),\n",
    "               arrowprops=dict(color='k', arrowstyle=\"->\", alpha=0.95), size=9)\n",
    "ax_2a.vlines(x=30.03, ymin=0,\n",
    "             ymax=timley_resetindex['Value of Payments'].max()/0.8,\n",
    "             color='k', linestyle='--',\n",
    "             alpha=0.5, linewidth=0.85)\n",
    "ax_2a.annotate('3/10/2010:\\nHammond signals\\n\"scaling back\" of\\n austerity',\n",
    "               xy=(30.03, timley_resetindex['Value of Payments'].max()/0.925),\n",
    "               xytext=(25, timley_resetindex['Value of Payments'].max()/0.925),\n",
    "               arrowprops=dict(color='k', arrowstyle=\"->\", alpha=0.95), size=9)\n",
    "ax_2a.set_ylim(0, timley_resetindex['Value of Payments'].max()/0.8)\n",
    "ax_2b.set_ylim(0, timley_resetindex['Number of Payments'].max()/0.8)\n",
    "ax_2a.spines['top'].set_visible(False)\n",
    "ax_2b.spines['top'].set_visible(False)\n",
    "ax_2a.axvspan(0, 5.66, alpha=0.075, color='grey')\n",
    "ax_2a.margins(0.0)\n",
    "ax_2a.spines['right'].set_visible(False)\n",
    "ax_2a.spines['left'].set_visible(False)\n",
    "ax_2a.set_ylabel(\"Value of Payments (£)\", size=9)\n",
    "ax_2b.set_ylabel(\"Number of Payments\", size=9)\n",
    "for axis in ['top', 'bottom', 'left', 'right']:\n",
    "    ax_2a.spines[axis].set_linewidth(0.75)\n",
    "    ax_2b.spines[axis].set_linewidth(0.75)\n",
    "axC.plot(0, 0, '-r', color='#ff7f00', markersize=7, alpha=0.2,\n",
    "         markeredgecolor='k', markeredgewidth=0.5)\n",
    "leg = axC.legend(['Value (left)', 'Number (right)'],\n",
    "                 fontsize=8, loc='upper right', frameon=False)\n",
    "ax_2a.tick_params(labelsize=8)\n",
    "ax_2b.tick_params(labelsize=8)\n",
    "fig.savefig(os.path.abspath(\n",
    "    os.path.join('__file__', '../..','compile','figures',\n",
    "                 'timeline.pdf')), bbox_inches='tight')\n",
    "fig.savefig(os.path.abspath(\n",
    "    os.path.join('__file__', '../..','compile','figures',\n",
    "                 'timeline.png')),dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the Matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do the matches look like? Plot as seperate figures because of the way LaTeX uses subfigures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='ticks')\n",
    "f, (ax1) = plt.subplots(1, 1, figsize=(8, 8))\n",
    "h = sns.distplot(recon_sup[~pd.isnull(recon_sup['First Match'])]['First Score'],\n",
    "                 bins=44,\n",
    "                 kde_kws={\"color\": \"#fc8d62\",\n",
    "                          \"lw\": 2, \"label\": \"KDE Estimate\",\n",
    "                          \"alpha\": 1},\n",
    "                 hist_kws={\"color\": \"#2938a0\",\n",
    "                           \"alpha\": 0.5, \"label\": \"Frequency\",\n",
    "                           'edgecolor': 'k'},\n",
    "                 ax=ax1)\n",
    "h.set(ylabel=\"Frequency\")\n",
    "h.set_xlim(xmin=-10, xmax=100)\n",
    "h.plot([20, 20], [0, .1], color='r', linestyle='--', linewidth=0.75)\n",
    "h.plot([70, 70], [0, .1], color='r', linestyle='--', linewidth=0.75)\n",
    "h.legend(loc='center left', bbox_to_anchor=(-0.004, 0.925),frameon=True)\n",
    "h.axvspan(-20, 20, alpha=0.08, color='grey')\n",
    "h.axvspan(20, 70, alpha=0.04, color='grey')\n",
    "sns.despine(right=True, top=True, ax=ax1)\n",
    "f.savefig(os.path.abspath(\n",
    "    os.path.join('__file__', '../..','compile','figures',\n",
    "                 'mostmatch_and_safematch_a.pdf')),\n",
    "          bbox_inches='tight')\n",
    "f.savefig(os.path.abspath(\n",
    "    os.path.join('__file__', '../..','compile','figures',\n",
    "                 'mostmatch_and_safematch_a.png')), dpi=600, bbox_inches='tight')\n",
    "\n",
    "f, (ax1) = plt.subplots(1, 1, figsize=(8, 8))\n",
    "g = sns.regplot(x=\"First Score\", y=\"Second Score\", data=recon_sup,\n",
    "                fit_reg=False, ax=ax1, color='#2938a0', marker='+',\n",
    "                scatter_kws={'s':120, 'alpha':0.5})\n",
    "g.set_xlim(xmin=-10, xmax=100)\n",
    "g.set_ylim(ymin=-10, ymax=100)\n",
    "r2 = patches.Rectangle((0, -20), 7.5, 200, color = \"grey\",  alpha=0.08)\n",
    "t2 = mpl.transforms.Affine2D().rotate_deg(-45) + g.transData\n",
    "r2.set_transform(t2)\n",
    "g.add_patch(r2)\n",
    "r1 = patches.Rectangle((70, -10), -80, 110, color=\"grey\",  alpha=0.08)\n",
    "g.add_patch(r1)\n",
    "g.plot([-10, 100], [-10, 100], color='r', linestyle='--', linewidth=0.8)\n",
    "g.plot([0, 100], [-10, 90], color='r', linestyle='--', linewidth=0.8)\n",
    "g.plot([70, 70], [-10, 100], color='r', linestyle='--', linewidth=0.8)\n",
    "sns.despine(right=True, top=True, ax=ax1)\n",
    "f.savefig(os.path.abspath(\n",
    "    os.path.join('__file__', '../..','compile','figures',\n",
    "                 'mostmatch_and_safematch_b.pdf')), bbox_inches='tight')\n",
    "f.savefig(os.path.abspath(\n",
    "    os.path.join('__file__', '../..','compile','figures',\n",
    "                 'mostmatch_and_safematch_b.png')), dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating our Matching Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_clean = clean_matches(recon_sup, 'automated_safe')\n",
    "recon_clean['company_number'] = recon_clean['Best ID'].str.replace('/companies/gb/','')\n",
    "matched_clean = pd.merge(payments, recon_clean, how='left',\n",
    "                         left_on='supplier',\n",
    "                         right_on='RawSupplier').dropna(subset=['Best Match'])\n",
    "print('We matched ' + str(len(matched_clean)) + ' out of ' + str(len(payments)) +\n",
    "      ' payments in total (' + str(round(((len(matched_clean) /\n",
    "                                           len(payments)) * 100), 2)) + '%).')\n",
    "print('We matched £' + str(int(matched_clean['amount'].sum())) + ' out of ' +\n",
    "      '£' + str(int(payments['amount'].sum())) +\n",
    "      ' value in total (' + str(int(round(((matched_clean['amount'].sum() /\n",
    "                                        payments['amount'].sum()) *\n",
    "                                       100), 2))) + '%).')\n",
    "print('We matched ' + str(len(matched_clean['supplier'].unique())) +\n",
    "      ' out of ' + str(len(payments['supplier'].unique())) +\n",
    "      ' unique suppliers in total (' +\n",
    "      str(round(((len(matched_clean['supplier'].unique()) /\n",
    "                  len(payments['supplier'].unique())) * 100), 2)) + '%).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze which companies get what:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_numpays = pd.DataFrame(matched_clean.groupby(\n",
    "    ['Best Match']).size(), columns=['Number of Payments'])\n",
    "sup_value = pd.DataFrame(pd.DataFrame(matched_clean.groupby(['Best Match'])[\n",
    "                         'amount'].agg('sum'))).rename(\n",
    "    columns={'amount': 'Value of Payments'})\n",
    "sup_both = pd.concat([sup_value, sup_numpays], axis=1).reset_index()\n",
    "recon_sup_for_match = recon_sup[['Best Match','Postcode','SIC Code','Type',\n",
    "                                 'First Score',\n",
    "                                 'Best ID']].drop_duplicates(subset='Best Match')\n",
    "sup_both = pd.merge(sup_both, recon_sup_for_match, how='left',\n",
    "                    left_on='Best Match', right_on='Best Match')\n",
    "sup_both = sup_both.sort_values(ascending=False, by='Value of Payments')[0:20]\n",
    "sup_both['ID'] = sup_both['Best ID'].str.replace('/companies/gb/', '')\n",
    "sup_both['Best Match'] = sup_both['Best Match'].str.title()\n",
    "sup_both = sup_both.set_index('Best Match')\n",
    "sup_both['SIC Code'] = sup_both['SIC Code'].str.replace(\"[\", '')\n",
    "sup_both['SIC Code'] = sup_both['SIC Code'].str.replace(']', '')\n",
    "sup_both['SIC Code'] = sup_both['SIC Code'].str.replace(\"'\", \"\")\n",
    "sup_both[['Value of Payments', 'Number of Payments',\n",
    "          'Postcode', 'SIC Code', 'Type']].style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split this across departments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depts_df = pd.DataFrame(columns=['Files', 'Spend (£m)', 'Total Payments',\n",
    "                                 '% to Prviate', 'Most Frequent PS Supplier'],\n",
    "                        index=payments['dept'].unique())\n",
    "for dept in matched_clean['dept'].unique():\n",
    "    depts_df.loc[dept, 'Files'] = len(payments[payments['dept'] ==\n",
    "                                               dept]['file'].unique())\n",
    "    depts_df.loc[dept, 'Spend (£m)'] = round(\n",
    "        payments[payments['dept'] == dept]['amount'].sum() / 1000000, 2)\n",
    "    depts_df.loc[dept, 'Total Payments'] = len(\n",
    "        payments[payments['dept'] == dept])\n",
    "    depts_df.loc[dept,\n",
    "                 'Most Frequent PS Supplier'] = matched_clean[matched_clean['dept']\n",
    "                                                      == dept]['Best Match'].value_counts().sort_values(ascending=False).index[0]\n",
    "    depts_df.loc[dept, '% to Prviate'] = round((matched_clean[matched_clean['dept'] ==\n",
    "                                                        dept]['amount'].sum(\n",
    "    ) / payments[payments['dept'] == dept]['amount'].sum()) * 100, 2)\n",
    "\n",
    "depts_df.sort_values(by='Spend (£m)',ascending=False)[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Across SIC categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.abspath(\n",
    "    os.path.join('__file__', '../..', 'data', 'output',\n",
    "                 'master', 'Single_SICs.tsv')), 'w') as sicfile:\n",
    "    sicfile.write('amount\\tdept\\tsic\\n')\n",
    "    for index, row in matched_clean.iterrows():\n",
    "        if pd.isnull(row['SIC Code']) is False:\n",
    "            for sic in row['SIC Code'].split(','):\n",
    "                sic = re.findall('\\\\b\\\\d+\\\\b', sic)[0]\n",
    "                sicfile.write(str(row['amount']) + '\\t' + \n",
    "                              row['dept'] + '\\t' + str(sic)+'\\n')\n",
    "sicfile = pd.read_csv(os.path.abspath(\n",
    "    os.path.join('__file__',\n",
    "                 '../..',\n",
    "                 'data',\n",
    "                 'output',\n",
    "                 'master',\n",
    "                 'Single_SICs.tsv')), sep = '\\t', encoding='latin-1')\n",
    "sicfile = sicfile[sicfile['amount']>25000]\n",
    "replacedict = pd.read_csv((os.path.abspath(\n",
    "    os.path.join('__file__', '../..', 'data', 'support', 'sic_renamer.csv'))),\n",
    "                          header=None,\n",
    "                          dtype={0: str}).set_index(0).squeeze().to_dict()\n",
    "for key, value in replacedict.items():\n",
    "    sicfile['sic'] = sicfile['sic'].replace(int(key),value)\n",
    "    \n",
    "sup_value = pd.DataFrame(pd.DataFrame(matched_clean.groupby(['Best Match'])['amount'].agg('sum')))\n",
    "uniquedepts = sicfile['dept'].unique()\n",
    "top_sics = pd.DataFrame(sicfile.groupby(['sic'])['amount'].agg('sum')).sort_values(by='amount',\n",
    "                                                                                   ascending=False)[0:37].index\n",
    "sicdept_df = pd.DataFrame(columns = top_sics, index = uniquedepts)\n",
    "for dept in uniquedepts:\n",
    "    for sic in list(sicdept_df):\n",
    "        sicdept_df.loc[dept,sic] = (sicfile[(sicfile['sic']==sic) &\n",
    "                                            (sicfile['dept']==dept)]['amount'].sum()/depts_df.loc[dept,'Files'])\n",
    "fig, ax = plt.subplots(figsize=(16,11))\n",
    "sicdept_df=sicdept_df.astype(float)\n",
    "sicdept_df[sicdept_df <= 0] = 1\n",
    "log_norm = LogNorm(vmin=sicdept_df.min().min(), vmax=sicdept_df.max().max())\n",
    "cbar_ticks = [math.pow(10, i) for i in range(math.floor(math.log10(sicdept_df.min().min())),\n",
    "                                             1+math.ceil(math.log10(sicdept_df.max().max())))]\n",
    "cbar_ax = fig.add_axes([.915, 0.125, .025, .755])\n",
    "g = sns.heatmap(sicdept_df,\n",
    "                linewidths=0.25,\n",
    "                linecolor='k',\n",
    "                cmap=\"RdBu_r\",\n",
    "                cbar_ax = cbar_ax,\n",
    "                ax = ax,\n",
    "                norm=log_norm,\n",
    "                cbar_kws={\"ticks\": cbar_ticks, 'label': 'Payment Value Per File (£)'})\n",
    "g.set_ylabel('');\n",
    "g.set_xlabel('');\n",
    "fig = g.get_figure()\n",
    "fig.savefig(os.path.abspath(\n",
    "    os.path.join('__file__', '../..','compile','figures',\n",
    "                 'sic_dept_heatmap.pdf')), bbox_inches='tight')\n",
    "fig.savefig(os.path.abspath(\n",
    "    os.path.join('__file__', '../..','compile','figures',\n",
    "                 'sic_dept_heatmap.png')), dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sociological Stratification of Officers and PSCs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load datasets first to reduce computational time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_psc = pd.read_csv(os.path.abspath(\n",
    "    os.path.join('__file__', '../..', 'data', 'companies_house',\n",
    "                 'psc_flatfile.tsv')),\n",
    "    encoding=\"ISO-8859-1\", sep='\\t', error_bad_lines=False,\n",
    "                    dtype={'company_number': str,\n",
    "                           'forename':str,\n",
    "                           'nationality':str,\n",
    "                           'date_of_birth':object},\n",
    "                    usecols=['company_number',\n",
    "                             'date_of_birth',\n",
    "                             'forename',\n",
    "                             'nationality'])\n",
    "ch_officers = pd.read_csv(os.path.abspath(\n",
    "    os.path.join('__file__', '../..', 'data', 'companies_house',\n",
    "                 'ch_full_officers.tsv')),\n",
    "    encoding=\"ISO-8859-1\", sep='\\t', error_bad_lines=False, \n",
    "                          warn_bad_lines = False,\n",
    "                dtype={'CompanyNumber': str,\n",
    "                       'Name': str,\n",
    "                       'Nationality':str},\n",
    "                usecols = ['CompanyNumber',\n",
    "                           'Name',\n",
    "                           'Nationality',\n",
    "                           'Date of Birth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_officers_age = ch_officers[ch_officers['Date of Birth'].notnull()]\n",
    "ch_officers_age['Evaluated Date'] = ch_officers_age['Date of Birth'].apply(lambda x: dict(eval(x)))\n",
    "ch_officers_age_uni = pd.DataFrame(ch_officers_age['Date of Birth'].drop_duplicates(),columns=['Date of Birth'])\n",
    "ch_officers_age_uni['Evaluated Date'] = ch_officers_age_uni['Date of Birth'].apply(lambda x: dict(eval(x)))\n",
    "ch_officers_age_uni = pd.merge(ch_officers_age_uni['Evaluated Date'].apply(pd.Series),\n",
    "                                      ch_officers_age_uni,left_index=True,right_index=True)\n",
    "ch_officers_age = pd.merge(ch_officers_age, ch_officers_age_uni, left_on='Date of Birth',\n",
    "                          right_on='Date of Birth',how='left')\n",
    "ch_officers_age = ch_officers_age[(ch_officers_age['year'] >= 1918)\n",
    "                          & (ch_officers_age['year'] <= 2018)]\n",
    "ch_officers_age['Cleaned Date'] = ch_officers_age['year'].map(\n",
    "    str) + '-' + ch_officers_age['month'].map(str) + '-01'\n",
    "ch_officers_age['Age'] = pd.to_datetime(\n",
    "    'today').year - pd.to_datetime(ch_officers_age['Cleaned Date']).dt.year\n",
    "ch_officers_age = ch_officers_age[ch_officers_age['Age'].notnull()]\n",
    "recon_officers_age = pd.merge(pd.DataFrame(recon_clean['company_number'].drop_duplicates()),\n",
    "                                ch_officers_age, how='left', left_on='company_number',\n",
    "                                right_on='CompanyNumber')\n",
    "recon_officers_age = recon_officers_age[recon_officers_age['Age'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_psc_age = ch_psc[ch_psc['date_of_birth'].notnull()]\n",
    "ch_psc_age['Evaluated Date'] = ch_psc_age['date_of_birth'].apply(lambda x: dict(eval(x)))\n",
    "ch_psc_age_uni = pd.DataFrame(ch_psc_age['date_of_birth'].drop_duplicates(),columns=['date_of_birth'])\n",
    "ch_psc_age_uni['Evaluated Date'] = ch_psc_age_uni['date_of_birth'].apply(lambda x: dict(eval(x)))\n",
    "ch_psc_age_uni = pd.merge(ch_psc_age_uni['Evaluated Date'].apply(pd.Series),\n",
    "                          ch_psc_age_uni,left_index=True,right_index=True)\n",
    "ch_psc_age = pd.merge(ch_psc_age, ch_psc_age_uni, left_on='date_of_birth',\n",
    "                          right_on='date_of_birth',how='left')\n",
    "ch_psc_age = ch_psc_age[(ch_psc_age['year'] >= 1918)\n",
    "                          & (ch_psc_age['year'] <= 2018)]\n",
    "ch_psc_age['Cleaned Date'] = ch_psc_age['year'].map(\n",
    "    str) + '-' + ch_psc_age['month'].map(str) + '-01'\n",
    "ch_psc_age['Age'] = pd.to_datetime(\n",
    "    'today').year - pd.to_datetime(ch_psc_age['Cleaned Date']).dt.year\n",
    "ch_psc_age = ch_psc_age[ch_psc_age['Age'].notnull()]\n",
    "recon_psc_age = pd.merge(pd.DataFrame(recon_clean['company_number'].drop_duplicates()),\n",
    "                                ch_psc_age, how='left', left_on='company_number',\n",
    "                                right_on='company_number')\n",
    "recon_psc_age = recon_psc_age[recon_psc_age['Age'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='ticks')\n",
    "f, (ax1) = plt.subplots(1, 1, figsize=(8,6))\n",
    "g = sns.distplot(ch_officers_age['Age'], ax=ax1,\n",
    "                 kde_kws={'gridsize':500},\n",
    "                 hist_kws={'color':'#377eb8'},\n",
    "                 label = 'Companies House')\n",
    "g = sns.distplot(recon_officers_age['Age'], ax=ax1,\n",
    "                 kde_kws={'gridsize':500},\n",
    "                 hist_kws={'color':'#ff7f00'},\n",
    "                 label = 'Reconciled Officers')\n",
    "ax1.set_ylabel(\"Normalized Frequency\",fontsize=12)\n",
    "ax1.set_xlabel(\"Age\",fontsize=12)\n",
    "sns.despine()\n",
    "g.legend(loc='upper left',edgecolor='k',frameon=False)\n",
    "f.savefig(os.path.abspath(\n",
    "    os.path.join('__file__', '../..','compile','figures',\n",
    "                 'officers_age.pdf')), bbox_inches='tight')\n",
    "f.savefig(os.path.abspath(\n",
    "    os.path.join('__file__', '../..','compile','figures',\n",
    "                 'officers_age.png')), dpi=600, bbox_inches='tight')\n",
    "\n",
    "f, (ax1) = plt.subplots(1, 1, figsize=(8,6))\n",
    "g = sns.distplot(ch_psc_age['Age'], ax=ax1,\n",
    "                 kde_kws={'gridsize':500},\n",
    "                 hist_kws={'color':'#377eb8'},\n",
    "                 label = 'Companies House')\n",
    "g = sns.distplot(recon_psc_age['Age'], ax=ax1,\n",
    "                 kde_kws={'gridsize':500},\n",
    "                 hist_kws={'color':'#ff7f00'},\n",
    "                 label = 'Reconciled Officers')\n",
    "ax1.set_ylabel(\"Normalized Frequency\",fontsize=12)\n",
    "ax1.set_xlabel(\"Age\",fontsize=12)\n",
    "sns.despine()\n",
    "g.legend(loc='upper left',edgecolor='k',frameon=False)\n",
    "f.savefig(os.path.abspath(\n",
    "    os.path.join('__file__', '../..','compile','figures',\n",
    "                 'psc_age.pdf')), bbox_inches='tight')\n",
    "f.savefig(os.path.abspath(\n",
    "    os.path.join('__file__', '../..','compile','figures',\n",
    "                 'psc_age.png')), dpi=600, bbox_inches='tight')\n",
    "\n",
    "\n",
    "print(ch_officers_age['Age'].mean())\n",
    "print(recon_officers_age['Age'].mean())\n",
    "print(ch_psc_age['Age'].mean())\n",
    "print(recon_psc_age['Age'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_officer_names(x):\n",
    "    try:\n",
    "        if len(x.split(' '))>=1:\n",
    "            return x.split(' ')[1]\n",
    "    except IndexError:\n",
    "        pass\n",
    "\n",
    "ch_officers_gen = ch_officers[ch_officers['Name'].notnull()]\n",
    "ch_officers_gen['Forename'] = ch_officers_gen['Name'].map(\n",
    "    lambda x: clean_officer_names(x))\n",
    "ch_officers_gen['CleanGender'] = ch_officers_gen['Forename'].map(\n",
    "    lambda x: gendet.get_gender(x))\n",
    "ch_officers_gen['MaleFemale'] = ch_officers_gen['CleanGender'].str.replace(\n",
    "    'mostly_', '')\n",
    "ch_officers_gen['isfemale'] = np.where(\n",
    "    ch_officers_gen['MaleFemale'] == 'female', 1, 0)\n",
    "ch_officers_gen = ch_officers_gen[(ch_officers_gen['MaleFemale'] == 'male') | (\n",
    "    ch_officers_gen['MaleFemale'] == 'female')]\n",
    "\n",
    "recon_officers_gen = pd.merge(pd.DataFrame(recon_clean['company_number'].drop_duplicates()),\n",
    "                                ch_officers_gen, how='left', left_on='company_number',\n",
    "                                right_on='CompanyNumber')\n",
    "recon_officers_gen = recon_officers_gen[(recon_officers_gen['MaleFemale'] == 'male') | (\n",
    "    recon_officers_gen['MaleFemale'] == 'female')]\n",
    "\n",
    "print(ch_officers_gen['isfemale'].mean())\n",
    "print(recon_officers_gen['isfemale'].mean())\n",
    "print(len(recon_officers_gen))\n",
    "print(len(recon_clean['company_number'].drop_duplicates()))\n",
    "print(len(recon_officers_gen['company_number'].drop_duplicates()))\n",
    "print(len(ch_officers['CompanyNumber'].drop_duplicates()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_psc_names(x):\n",
    "    if ('ltd' not in x.lower()) and ('limited' not in x.lower()):\n",
    "        x=x.replace('.','').strip()\n",
    "        x=x.replace('Mrs ','').strip()\n",
    "        x=x.replace('Mr ','').strip()\n",
    "        x=x.replace('Wing Commander','').strip()\n",
    "        x=x.replace('Miss ','').strip()\n",
    "        x=x.replace('Dr ','').strip()\n",
    "        x=x.replace('Ms ','').strip()\n",
    "        if len(x.split(' ')[0].title())>2:\n",
    "            return x.split(' ')[0].title()\n",
    "\n",
    "ch_psc_gen = ch_psc[ch_psc['name'].notnull()]\n",
    "ch_psc_gen['Forename'] = ch_psc_gen['name'].map(\n",
    "    lambda x: clean_psc_names(x))\n",
    "ch_psc_gen['CleanGender'] = ch_psc_gen['Forename'].map(\n",
    "    lambda x: gendet.get_gender(x))\n",
    "ch_psc_gen['MaleFemale'] = ch_psc_gen['CleanGender'].str.replace(\n",
    "    'mostly_', '')\n",
    "ch_psc_gen['isfemale'] = np.where(\n",
    "    ch_psc_gen['MaleFemale'] == 'female', 1, 0)\n",
    "ch_psc_gen = ch_psc_gen[(ch_psc_gen['MaleFemale'] == 'male') | (\n",
    "    ch_psc_gen['MaleFemale'] == 'female')]\n",
    "\n",
    "recon_psc_gen = pd.merge(pd.DataFrame(recon_clean['company_number'].drop_duplicates()),\n",
    "                                ch_psc_gen, how='left', left_on='company_number',\n",
    "                                right_on='company_number')\n",
    "recon_psc_gen = recon_psc_gen[(recon_psc_gen['MaleFemale'] == 'male') | (\n",
    "    recon_psc_gen['MaleFemale'] == 'female')]\n",
    "\n",
    "print(ch_psc_gen['isfemale'].mean())\n",
    "print(recon_psc_gen['isfemale'].mean())\n",
    "print(len(recon_psc_gen))\n",
    "print(len(recon_clean['company_number'].drop_duplicates()))\n",
    "print(len(recon_psc_gen['company_number'].drop_duplicates()))\n",
    "print(len(ch_psc['company_number'].drop_duplicates()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nationalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_nationalities(x):\n",
    "    x = x.lower().replace('english','british')\n",
    "    x = x.lower().replace('scottish','british')\n",
    "    x = x.lower().replace('welsh','british')\n",
    "    x = x.lower().replace('northern irish','british')\n",
    "    x = x.lower().replace('united kingdom', 'british')\n",
    "    x = x.lower().replace('.','')\n",
    "    x = x.lower().replace(',','')\n",
    "    if x.lower()[0:2] == 'uk':\n",
    "        x = 'british'\n",
    "    return x.title()\n",
    "\n",
    "ch_psc_nat = ch_psc[ch_psc['nationality'].notnull()]\n",
    "ch_psc_nat['nationality'] = ch_psc_nat['nationality'].map(lambda x: clean_nationalities(x))\n",
    "len_ch_psc_nat = len(ch_psc_nat[ch_psc_nat['nationality'].notnull()])\n",
    "ch_psc_nat_pcs = ch_psc_nat['nationality'].value_counts().divide(len_ch_psc_nat/100)\n",
    "ch_psc_nat_pcs = ch_psc_nat_pcs.sort_values(ascending=False)\n",
    "\n",
    "recon_psc_nat = pd.merge(pd.DataFrame(recon_clean['company_number'].drop_duplicates()),\n",
    "                                ch_psc_nat, how='left', left_on='company_number',\n",
    "                                right_on='company_number')\n",
    "recon_psc_nat = recon_psc_nat[recon_psc_nat['nationality'].notnull()]\n",
    "recon_psc_nat['nationality'] = recon_psc_nat['nationality'].map(lambda x: clean_nationalities(x))\n",
    "len_recon_psc_nat = len(recon_psc_nat[recon_psc_nat['nationality'].notnull()])\n",
    "recon_psc_nat_pcs = recon_psc_nat['nationality'].value_counts().divide(len_recon_psc_nat/100)\n",
    "recon_psc_nat_pcs = recon_psc_nat_pcs.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_officers_nat = ch_officers[ch_officers['Nationality'].notnull()]\n",
    "ch_officers_nat['Nationality'] = ch_officers_nat['Nationality'].map(lambda x: clean_nationalities(x))\n",
    "len_ch_officers_nat = len(ch_officers_nat[ch_officers_nat['Nationality'].notnull()])\n",
    "ch_officers_nat_pcs = ch_officers_nat['Nationality'].value_counts().divide(len_ch_officers_nat/100)\n",
    "ch_officers_nat_pcs = ch_officers_nat_pcs.sort_values(ascending=False)\n",
    "\n",
    "recon_officers_nat = pd.merge(pd.DataFrame(recon_clean['company_number'].drop_duplicates()),\n",
    "                                ch_officers_nat, how='left', left_on='company_number',\n",
    "                                right_on='CompanyNumber')\n",
    "recon_officers_nat = recon_officers_nat[recon_officers_nat['Nationality'].notnull()]\n",
    "recon_officers_nat['Nationality'] = recon_officers_nat['Nationality'].map(lambda x: clean_nationalities(x))\n",
    "len_recon_officers_nat = len(recon_officers_nat[recon_officers_nat['Nationality'].notnull()])\n",
    "recon_officers_nat_pcs = recon_officers_nat['Nationality'].value_counts().divide(len_recon_officers_nat/100)\n",
    "recon_officers_nat_pcs = recon_officers_nat_pcs.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Countries of Residence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_countries(x):\n",
    "    x = x.lower().replace('england','united kingdom')\n",
    "    x = x.lower().replace('scotland','united kingdom')\n",
    "    x = x.lower().replace('wales','united kingdom')\n",
    "    x = x.lower().replace('northern ireland','united kingdom')\n",
    "    x = x.lower().replace('britain','united kingdom')\n",
    "    x = x.lower().replace('.','')\n",
    "    x = x.lower().replace(',','')\n",
    "    if x.lower()[0:2] == 'gb':\n",
    "        x = 'united kingdom'\n",
    "    return x.title()\n",
    "\n",
    "ch_psc_cou = ch_psc[ch_psc['country_of_residence'].notnull()]\n",
    "ch_psc_cou['country_of_residence'] = ch_psc_cou['country_of_residence'].map(lambda x: clean_countries(x))\n",
    "len_ch_psc_cou = len(ch_psc_cou[ch_psc_cou['country_of_residence'].notnull()])\n",
    "ch_psc_cou_pcs = ch_psc_cou['country_of_residence'].value_counts().divide(len_ch_psc_cou/100)\n",
    "ch_psc_cou_pcs = ch_psc_cou_pcs.sort_values(ascending=False)\n",
    "\n",
    "\n",
    "recon_psc_cou = pd.merge(pd.DataFrame(recon_clean['company_number'].drop_duplicates()),\n",
    "                                ch_psc_cou, how='left', left_on='company_number',\n",
    "                                right_on='company_number')\n",
    "recon_psc_cou = recon_psc_cou[recon_psc_cou['country_of_residence'].notnull()]\n",
    "len_recon_psc_cou = len(recon_psc_cou[recon_psc_cou['country_of_residence'].notnull()])\n",
    "recon_psc_cou_pcs = recon_psc_cou['country_of_residence'].value_counts().divide(len_recon_psc_cou/100)\n",
    "recon_psc_cou_pcs = recon_psc_cou_pcs.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_officers_cou = ch_officers[ch_officers['Country of Residence'].notnull()]\n",
    "ch_officers_cou['Country of Residence'] = ch_officers_cou['Country of Residence'].map(lambda x: clean_countries(x))\n",
    "len_ch_officers_cou = len(ch_officers_cou[ch_officers_cou['Country of Residence'].notnull()])\n",
    "ch_officers_cou_pcs = ch_officers_cou['Country of Residence'].value_counts().divide(len_ch_officers_cou/100)\n",
    "ch_officers_cou_pcs = ch_officers_cou_pcs.sort_values(ascending=False)\n",
    "\n",
    "recon_officers_cou = pd.merge(pd.DataFrame(recon_clean['company_number'].drop_duplicates()),\n",
    "                                ch_officers_cou, how='left', left_on='company_number',\n",
    "                                right_on='CompanyNumber')\n",
    "recon_officers_cou = recon_officers_cou[recon_officers_cou['Country of Residence'].notnull()]\n",
    "len_recon_officers_cou = len(recon_officers_cou[recon_officers_cou['Country of Residence'].notnull()])\n",
    "recon_officers_cou_pcs = recon_officers_cou['Country of Residence'].value_counts().divide(len_recon_officers_cou/100)\n",
    "recon_officers_cou_pcs = recon_officers_cou_pcs.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot residences and nationalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "df_resi_nat = pd.DataFrame(index=['CH','Recon'],\n",
    "                           columns=['Officer Countries',\n",
    "                                    'Officer Nationalities',\n",
    "                                    'PSC Countries',\n",
    "                                    'PSC Nationalities'])\n",
    "\n",
    "df_resi_nat.loc['Recon','Officer Countries'] = 100-recon_officers_cou_pcs['United Kingdom']\n",
    "df_resi_nat.loc['CH','Officer Countries'] = 100-ch_officers_cou_pcs['United Kingdom']\n",
    "df_resi_nat.loc['Recon','PSC Countries'] = 100-recon_psc_cou_pcs['United Kingdom']\n",
    "df_resi_nat.loc['CH','PSC Countries'] = 100-ch_psc_cou_pcs['United Kingdom']\n",
    "df_resi_nat.loc['Recon','Officer Nationalities'] = 100-recon_officers_nat_pcs['British']\n",
    "df_resi_nat.loc['CH','Officer Nationalities'] = 100-ch_officers_nat_pcs['British']\n",
    "df_resi_nat.loc['Recon','PSC Nationalities'] = 100-recon_psc_nat_pcs['British']\n",
    "df_resi_nat.loc['CH','PSC Nationalities'] = 100-ch_psc_nat_pcs['British']\n",
    "\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=4,figsize=(14,7))\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "a = df_resi_nat['Officer Nationalities'].plot(kind='bar',\n",
    "                                              ax=axes[0],\n",
    "                                              color=['#377eb8','#ff7f00'],\n",
    "                                              alpha=0.5,\n",
    "                                              edgecolor='k',\n",
    "                                              linewidth=2)\n",
    "b = df_resi_nat['Officer Countries'].plot(kind='bar',\n",
    "                                          ax=axes[1],\n",
    "                                          color=['#377eb8','#ff7f00'],\n",
    "                                          alpha=0.5,\n",
    "                                          edgecolor='k',\n",
    "                                          linewidth=2)\n",
    "c = df_resi_nat['PSC Nationalities'].plot(kind='bar',\n",
    "                                          ax=axes[2],\n",
    "                                          color=['#377eb8','#ff7f00'],\n",
    "                                          alpha=0.5,\n",
    "                                          edgecolor='k',\n",
    "                                          linewidth=2)\n",
    "d = df_resi_nat['PSC Countries'].plot(kind='bar',\n",
    "                                      ax=axes[3],\n",
    "                                      color=['#377eb8','#ff7f00'],\n",
    "                                      alpha=0.5,\n",
    "                                      edgecolor='k',\n",
    "                                      linewidth=2,\n",
    "                                      legend=True)\n",
    "\n",
    "\n",
    "CH = mpatches.Patch(facecolor='#377eb8', label='Companies House',alpha=0.5,edgecolor='k',linewidth=1.5)\n",
    "Recon = mpatches.Patch(facecolor='#ff7f00', label='Reconciled Supplier',alpha=0.5,edgecolor='k',linewidth=1.5)\n",
    "plt.legend(handles=[CH,Recon], loc=2,fontsize=13, edgecolor='k')\n",
    "\n",
    "a.set_xlabel(\"Officer Nationalities\",fontsize=14,labelpad=10)\n",
    "b.set_xlabel(\"Officer Countries\",fontsize=14,labelpad=10)\n",
    "c.set_xlabel(\"PSC Nationalities\",fontsize=14,labelpad=10)\n",
    "d.set_xlabel(\"PSC Countries\",fontsize=14,labelpad=10)\n",
    "\n",
    "for axy in [a,b,c,d]:\n",
    "    axy.set_ylim(0, df_resi_nat.max().max()+2)\n",
    "    axy.axes.get_xaxis().set_ticks([])\n",
    "    for p in axy.patches:\n",
    "        axy.annotate(str(round(p.get_height(),3))+'%', (p.get_x(), p.get_height() + 0.4))\n",
    "    if axy!=a:\n",
    "        sns.despine(ax=axy, left=True, bottom = False, right = True)\n",
    "        #axy.yaxis.set_tick_position('none') \n",
    "        axy.axes.get_yaxis().set_visible(False)\n",
    "    else:\n",
    "        sns.despine(ax=axy, left=False, bottom = False, right = True)\n",
    "        axy.set_ylabel(\"Percent International\",fontsize=14)\n",
    "        vals = axy.get_yticks()\n",
    "        axy.set_yticklabels(['{:,.0%}'.format(x/100) for x in vals],fontsize=12)\n",
    "\n",
    "fig.subplots_adjust(hspace=25)\n",
    "fig.savefig(os.path.abspath(\n",
    "    os.path.join('__file__', '../..','compile','figures',\n",
    "                 'countries_and_nationalities.pdf')), bbox_inches='tight')\n",
    "fig.savefig(os.path.abspath(\n",
    "    os.path.join('__file__', '../..','compile','figures',\n",
    "                 'countries_and_nationalities.png')), dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Occupations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_occupations(x):\n",
    "    x = x.replace('.','')\n",
    "    x = x.replace(',','')\n",
    "    return x.title()\n",
    "\n",
    "ch_officers_occ = ch_officers[ch_officers['Occupation'].notnull()]\n",
    "ch_officers_occ = ch_officers_occ[ch_officers_occ['Occupation']!='Director']\n",
    "ch_officers_occ = ch_officers_occ[ch_officers_occ['Occupation']!='Company Director']\n",
    "ch_officers_occ = ch_officers_occ[ch_officers_occ['Occupation']!='None']\n",
    "ch_officers_occ['Occupation'] = ch_officers_occ['Occupation'].map(lambda x: clean_occupations(x))\n",
    "len_ch_officers_occ = len(ch_officers_occ[ch_officers_occ['Occupation'].notnull()])\n",
    "ch_officers_occ_pcs = ch_officers_occ['Occupation'].value_counts().divide(len_ch_officers_occ/100)\n",
    "ch_officers_occ_pcs = ch_officers_occ_pcs.sort_values(ascending=False)\n",
    "\n",
    "recon_officers_occ = pd.merge(pd.DataFrame(recon_clean['company_number'].drop_duplicates()),\n",
    "                                ch_officers_occ, how='left', left_on='company_number',\n",
    "                                right_on='CompanyNumber')\n",
    "len_recon_officers_occ = len(recon_officers_occ[recon_officers_occ['Occupation'].notnull()])\n",
    "recon_officers_occ_pcs = recon_officers_occ['Occupation'].value_counts().divide(len_recon_officers_occ/100)\n",
    "recon_officers_occ_pcs = recon_officers_occ_pcs.sort_values(ascending=False)\n",
    "\n",
    "both_officers_occ_pcs = pd.merge(pd.DataFrame(ch_officers_occ_pcs),\n",
    "                                 pd.DataFrame(recon_officers_occ_pcs),\n",
    "                                 left_index=True, right_index=True)\n",
    "both_officers_occ_pcs = both_officers_occ_pcs.rename({'Occupation_x':'CH Officers',\n",
    "                                                      'Occupation_y': 'Reconciled Officers'},axis=1)\n",
    "sns.set_style(\"ticks\")\n",
    "a = both_officers_occ_pcs[0:25].plot(kind='bar', figsize=(16,8),\n",
    "                                     color=['#377eb8','#ff7f00'],\n",
    "                                     alpha=0.5,\n",
    "                                     edgecolor='k',\n",
    "                                     linewidth=2)\n",
    "a.set_ylabel(\"Percent in Occupation\",fontsize=14)\n",
    "vals = a.get_yticks()\n",
    "a.set_yticklabels(['{:,.0%}'.format(x/100) for x in vals],fontsize=12)\n",
    "plt.xticks(fontsize=12, rotation=90)\n",
    "plt.legend(loc='upper right',fontsize=13, edgecolor='k')\n",
    "sns.despine()\n",
    "\n",
    "fig = a.get_figure()\n",
    "\n",
    "fig.savefig(os.path.abspath(\n",
    "    os.path.join('__file__', '../..','compile','figures',\n",
    "                 'officer_occupations.pdf')), bbox_inches='tight')\n",
    "fig.savefig(os.path.abspath(\n",
    "    os.path.join('__file__', '../..','compile','figures',\n",
    "                 'officer_occupations.png')), dpi=600, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
